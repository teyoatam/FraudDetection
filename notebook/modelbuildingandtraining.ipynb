{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "pre_credit_data = pd.read_csv('../data/preprocessed_creditcard_data.csv')\n",
    "pre_fraud_data_df = pd.read_csv('../data/preprocessed_fraud_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target separation\n",
    "X_credit = pre_credit_data.drop(columns=['Class'])\n",
    "y_credit = pre_credit_data['Class']\n",
    "\n",
    "X_fraud = pre_fraud_data_df.drop(columns=['class'])\n",
    "y_fraud = pre_fraud_data_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract datetime features month and year \n",
    "def extract_datetime_features(df, datetime_column):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[datetime_column] = pd.to_datetime(df_copy[datetime_column])\n",
    "    df_copy['year'] = df_copy[datetime_column].dt.year\n",
    "    df_copy['month'] = df_copy[datetime_column].dt.month\n",
    "    df_copy = df_copy.drop(columns=[datetime_column])\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_column = 'purchase_time' \n",
    "X_fraud = extract_datetime_features(X_fraud, datetime_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = X_fraud.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_fraud.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numeric and categorical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_fraud = preprocessor.fit_transform(X_fraud)\n",
    "\n",
    "# Train-test split\n",
    "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(X_credit, y_credit, test_size=0.2, random_state=42)\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"MLP\": MLPClassifier(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"AUC-ROC:\", roc_auc_score(y_test, y_prob))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log experiments using MLflow\n",
    "def log_experiment(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"{model_name} logged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Shape: (151112, 15)\n",
      "Target Shape: (151112,)\n",
      "\n",
      "Training Features Shape: (120889, 15)\n",
      "Testing Features Shape: (30223, 15)\n",
      "Training Target Shape: (120889,)\n",
      "Testing Target Shape: (30223,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Feature and Target Separation\n",
    "# Assuming 'class' is the target variable and other columns are features\n",
    "X = pre_fraud_data_df.drop(columns=['class'])  # Features\n",
    "y = pre_fraud_data_df['class']                  # Target variable\n",
    "\n",
    "# Display the shapes of features and target\n",
    "print(f\"\\nFeatures Shape: {X.shape}\")\n",
    "print(f\"Target Shape: {y.shape}\")\n",
    "\n",
    "# 2. Train-Test Split\n",
    "# Splitting the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(f\"\\nTraining Features Shape: {X_train.shape}\")\n",
    "print(f\"Testing Features Shape: {X_test.shape}\")\n",
    "print(f\"Training Target Shape: {y_train.shape}\")\n",
    "print(f\"Testing Target Shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Explanation:\n",
    "Load the Dataset: Reads Fraud_Data.csv into a DataFrame.\n",
    "Feature and Target Separation:\n",
    "The features (X) are defined by dropping the target variable class.\n",
    "The target variable (y) is defined as the class column.\n",
    "Train-Test Split:\n",
    "The dataset is split into training (80%) and testing (20%) sets using train_test_split from sklearn.model_selection.\n",
    "The stratify=y argument ensures that the split maintains the same proportion of classes in both the training and test sets.\n",
    "Display Results: The shapes of the features and target variables for both the training and testing sets are printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models for fraud data:\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     27373\n",
      "           1       1.00      0.54      0.70      2850\n",
      "\n",
      "    accuracy                           0.96     30223\n",
      "   macro avg       0.98      0.77      0.84     30223\n",
      "weighted avg       0.96      0.96      0.95     30223\n",
      "\n",
      "AUC-ROC: 0.7643414915837798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 22:13:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression logged successfully.\n",
      "\n",
      "Decision Tree\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and log models for fraud data\n",
    "print(\"\\nEvaluating models for fraud data:\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    trained_model = train_and_evaluate(model, X_fraud_train, y_fraud_train, X_fraud_test, y_fraud_test)\n",
    "    log_experiment(name, trained_model, X_fraud_train, y_fraud_train, X_fraud_test, y_fraud_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and log models for credit card data\n",
    "print(\"Evaluating models for credit card data:\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    trained_model = train_and_evaluate(model, X_credit_train, y_credit_train, X_credit_test, y_credit_test)\n",
    "    log_experiment(name, trained_model, X_credit_train, y_credit_train, X_credit_test, y_credit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, LSTM\n",
    "# CNN\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_credit_train.shape[1], 1)))\n",
    "# Add more layers as needed\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# LSTM\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(units=64, input_shape=(X_fraud_train.shape[1], 1)))\n",
    "# Add more layers as needed\n",
    "lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
